{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "front-marijuana",
   "metadata": {},
   "source": [
    "# 서약\n",
    "* 당연한 것을 아래와 같이 한번 다지고 가도록 하겠습니다. 아래 보고서는 **본인의 힘만으로 작성**해야하며, 다른 수강생에게 직접적인 질문, 복사 하는 행위는 모두 금지합니다 \n",
    "  * 예를 들어서, 본 프로젝트의 코드 셀을 완성하는데 직접적인 질문 또는 복사하는 경우는 모두 금지합니다\n",
    "  * 수업에서 제공한 코드, 노트북은 모두 재활용가능하며, 카피로 규정하지 않습니다\n",
    "  * 수업 자료 이외에 참고자료가 있다면, 출처와 사용 부분에 모두 표시하는 경우는 모두 합당한 자료로 인정하겠습니다\n",
    "  \n",
    "* 위에 대해서 모두 이해하고 동의했다면, 아래 `서약글`에 다음을 작성해주세요:\n",
    "\n",
    "\"본인은 위 서약글을 이해하고 동의하며, 프로젝트를 수행하는데 있어서 반칙을 할 경우 (제공자 포함) 본 프로젝트에 대한 점수가 반영되지 않는다는 것에 동의 합니다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-trouble",
   "metadata": {},
   "source": [
    "**서약서**\n",
    "\n",
    "이름: 최민기\n",
    "\n",
    "학번: 20165338\n",
    "\n",
    "서약글:  본인은 위 서약글을 이해하고 동의하며, 프로젝트를 수행하는데 있어서 반칙을 할 경우(제공자 포함)본 프로젝트에 대한 점수가 반영되지 않는다는 것에 동의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-jumping",
   "metadata": {},
   "source": [
    "# Final Project \n",
    "\n",
    "## Project: 새 품종 분류하기\n",
    "\n",
    "## Due date: 2021.06.15\n",
    "\n",
    "---\n",
    "\n",
    "* 아래 여러 셀에서 코드를 완성하는 부분을 수행하고, 설명을 요구하는 부분은 보고서에 설명을 최대한 자세하게 적어주세요. 기준은 본인이 이해하고 있다는 것을 표현할 수 있는 부분을 모두 적으시면 됩니다.\n",
    "  * 답을 작성하는 원칙은 **보고서**를 작성한다고 생각하시면 됩니다\n",
    "  * 내가 알고 있는 부분을 충실하게 **글로 표현** 하는 것 또한 중요한 연습입니다 \n",
    "  * 코드 작성은 **주석**으로 설명하시기 바랍니다\n",
    "  \n",
    "  \n",
    "> **제출방법**: \n",
    "* 보고서에는 코드 캡쳐 첨부이외에도, 각 코드를 작성하는 방법론과 설명을 작성해야하는 **서술형 문제**도 포함되어 있습니다.\n",
    "* 서술형 문제는 채점하는 중요한 기준이 됩니다. 성실하게 작성해주세요.\n",
    "* 서술형 문제에 대한 답변은 첨부된 보고서에 작성하면 됩니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-royal",
   "metadata": {},
   "source": [
    "### 목표: 앱을 위한 인공지능 알고리즘 개발 ^ㅡ^\n",
    "* 본 보고서에서는 모바일/웹앱을 위한 인공지능 알고리즘을 개발하라는 업무를 부여받았다고 가정합니다\n",
    "* 프로젝트가 완성본은, 사용자가 제공하는 image를 받아서 새의 종(種)을 예측합니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-trial",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-assumption",
   "metadata": {},
   "source": [
    "## Step 0: Import library\n",
    "\n",
    "- 필요하다 생각되는 라이브러리를 미리 import해 놓은 항목입니다.(참고)\n",
    "- 필요 없는 라이브러리를 제거하거나 필요한 라이브러리를 추가하셔도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "#train_on_gpu = False\n",
    "\n",
    "if not train_on_gpu:\n",
    "    device = 'cpu'\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    device = 'cuda'\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./imgs/train/\"  # 데이터 경로 설정\n",
    "# transform 정규화 하기 전 정확한 mean, std 값 확인하기 위해 사용하는 코드 \n",
    "# imageFolder로 데이터 불러오기\n",
    "train_ds = datasets.ImageFolder(root = train_path, transform=transforms.ToTensor())\n",
    "# 이미지 하나 당 RGB channel별로 mean과 std 계산 -> output은 총 데이터 개수\n",
    "meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x,_ in train_ds]\n",
    "stdRGB = [np.std(x.numpy(), axis=(1,2)) for x,_ in train_ds]\n",
    "\n",
    "# 이미지 각 mean과 std의 전체적인 평균 값\n",
    "meanR = np.mean([m[0] for m in meanRGB])\n",
    "meanG = np.mean([m[1] for m in meanRGB])\n",
    "meanB = np.mean([m[2] for m in meanRGB])\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])\n",
    "stdG = np.mean([s[1] for s in stdRGB])\n",
    "stdB = np.mean([s[2] for s in stdRGB])\n",
    "\n",
    "print(meanR, meanG, meanB)\n",
    "print(stdR, stdG, stdB)\n",
    "# https://deep-learning-study.tistory.com/475 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./imgs/train\"\n",
    "test_path = \"./imgs/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "train_transform = transforms.Compose([  # augmentation기능들을 순차적으로 시행하도록 묶어줌\n",
    "    transforms.Resize((240, 240)),  # 모든 이미지의 사이즈를 240*240으로 고정시켜주는 기능\n",
    "    transforms.RandomRotation (degrees=20),  # Random하게 이미지의 각도를 20으로 회전시키는 기능\n",
    "    transforms.RandomCrop((224,224)),  # 이미지에서 Random하게 crop(확대)하는 기능\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # 이미지를 50%확률로 좌우변환하는 기능\n",
    "#     transforms.RandomVerticalFlip(p=0.4),  # 이미지를 40%확률로 상하변환하는 기능\n",
    "    transforms.ToTensor(),  # Tensor로 변환\n",
    "    transforms.Normalize((0.4734, 0.4809, 0.4165), (0.1831, 0.1783, 0.1856)),  # 이미지 값 정규화\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4734, 0.4809, 0.4165), (0.1831, 0.1783, 0.1856)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-combining",
   "metadata": {},
   "source": [
    "## Step 3: Neural Network 생성\n",
    "- Pretrained model을 허용하지 않습니다. (직접 모델을 설계해 주세요)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "#코드작성\n",
    "#batchnorm은 학습하는파마리터가 있어서 파라미터가 늘어난다.감마랑 베타를 학습\n",
    "class ConvNet82(nn.Module):  # nn.Module를 상속받는 class 선언\n",
    "    def __init__(self):   # 자동으로 실행되는 첫번째 메소드인 __init__선언 // self는 자기자신의 인스턴스를 받음\n",
    "        super().__init__()  # 상속받은 nn.Module의 인스턴스를 임시로 불러오는 부분\n",
    "        # input : 3*224*224\n",
    "        # 3*3filter에 padding=1을 주면 이미지의 사이즈가 layer를 적용하기 전의 사이즈와 동일하다.\n",
    "        # BatchNorm2d는 각 Convolution layer를 거치고 난 후 정규화를 해주어 학습이 더 잘되는 효과를 일으킨다.\n",
    "        # MaxPool2d는 2*2filter에 stride2로 4개의 픽셀값 중 가장 큰 픽셀값을 가져오고 이미지의 size를 축소시켜 중요한 feature값만 뽑아내는 기능이다.\n",
    "        # 마지막으로 activation function인 ReLU를 적용하면 음의 값을 가진 데이터가 0으로 수렴한다.\n",
    "        # 각 conv2d layer를 지날때마다 output의 차원을 다음 layer의 input으로 적용해주어야 한다.\n",
    "        # ReLU에 True를 넣는 이유 : 메모리를 그 자리에서 직접 연산한다.(복사해서 불러오지 않아도 된다.)\n",
    "        self.cn1 = nn.Sequential(nn.Conv2d(3, 16, 3, padding=1),nn.BatchNorm2d(16),nn.ReLU(True),\n",
    "                                nn.Conv2d(16,16,3, padding=1),nn.BatchNorm2d(16),nn.ReLU(True))\n",
    "        # 모델을 더 딥하게 만들기 위해서 Maxpooling을 하기 전에 Convolution layer를 한개씩 더 추가해 주었다.\n",
    "        # 16*224*224\n",
    "        self.cn2 = nn.Sequential(nn.Conv2d(16, 32, 3, padding=1),nn.BatchNorm2d(32),nn.ReLU(True),\n",
    "                                 nn.Conv2d(32,32,3, padding=1),nn.BatchNorm2d(32),nn.MaxPool2d(2, 2),nn.ReLU(True))\n",
    "        # 32*112*112\n",
    "        self.cn3 = nn.Sequential(nn.Conv2d(32, 64, 3, padding=1),nn.BatchNorm2d(64),nn.ReLU(True),\n",
    "                                 nn.Conv2d(64, 64, 3, padding=1),nn.BatchNorm2d(64),nn.MaxPool2d(2, 2),nn.ReLU(True))\n",
    "        # 64*56*56\n",
    "        self.cn4 = nn.Sequential(nn.Conv2d(64, 128, 3, padding=1),nn.BatchNorm2d(128),nn.ReLU(True),\n",
    "                                 nn.Conv2d(128, 128, 3, padding=1),nn.BatchNorm2d(128),nn.MaxPool2d(2, 2),nn.ReLU(True))\n",
    "        # 128*28*28\n",
    "        self.cn5 = nn.Sequential(nn.Conv2d(128, 256, 3, padding=1),nn.BatchNorm2d(256),nn.ReLU(True),\n",
    "                                 nn.Conv2d(256, 256, 3, padding=1),nn.BatchNorm2d(256),nn.MaxPool2d(2, 2),nn.ReLU(True))\n",
    "        # 256*14*14\n",
    "        self.cn6 = nn.Sequential(nn.Conv2d(256, 512, 3, padding=1),nn.BatchNorm2d(512),nn.ReLU(True),\n",
    "                                 nn.Conv2d(512, 512, 3, padding=1),nn.BatchNorm2d(512),nn.MaxPool2d(2, 2),nn.ReLU(True))\n",
    "        # 512*7*7 = 25088\n",
    "        \n",
    "        self.fc1 = nn.Sequential(nn.Linear(25088, 1024), # Convolution layer를 거친 데이터를 1열로 펼쳐서 Fully Connected Layer 적용\n",
    "                                 nn.BatchNorm1d(1024),   # 1차원이므로 BatchNorm1d를 적용하여 데이터 정규화\n",
    "                                 nn.ReLU(True),          # activation function 적용\n",
    "                                 nn.Dropout(0.5),        # 간단하지만 아주 강력한 정규화(regularization) 방법으로 무작위 어떠한 확률로 퍼셉트론을 지워 편향을 억제\n",
    "                                  \n",
    "                                 nn.Linear(1024, 300),\n",
    "                                 nn.BatchNorm1d(300),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Dropout(0.5),\n",
    "                                  \n",
    "                                 nn.Linear(300, 15))     # 마지막 layer에는 ReLU와 Dropout을 사용하지 않는다.\n",
    "\n",
    "    def forward(self, x):  # nn.Module에 있는 함수로 ConvNet.forward()를 사용하지 않아도 실행된다. / forward path연산을 하는 함수\n",
    "        x = self.cn1(x)    # __init__에서 만든 모델들을 순차적으로 적용해준다. \n",
    "        x = self.cn2(x)\n",
    "        x = self.cn3(x)\n",
    "        x = self.cn4(x)\n",
    "        x = self.cn5(x)\n",
    "        x = self.cn6(x)\n",
    "        x = x.view(x.size(0),-1)  # conv2d layer를 적용시킨 데이터값들을 1차원으로 정렬\n",
    "        x = self.fc1(x)    # __init__함수에서 선언한 self.fc를 불러와서 만든 모델을 x에 대입\n",
    "\n",
    "        return x\n",
    "# model구성 확인\n",
    "model = ConvNet82()  # ConvNet()모델을 model에 적용\n",
    "\n",
    "model.to(device)   # model을 gpu사용하도록 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-legend",
   "metadata": {},
   "source": [
    " ## Step 4: Cost (Loss) Function 과 Optimizer 선택\n",
    " \n",
    " [loss function](http://pytorch.org/docs/stable/nn.html#loss-functions) 및 [optimizer](http://pytorch.org/docs/stable/optim.html)를 선택하여 코드를 완성하세요.\n",
    " \n",
    " 위 링크에서 다양한 Loss Function과 Optimize Function을 확인 할 수 있습니다\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-management",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-comparative",
   "metadata": {},
   "source": [
    "## Step 5: 구성한 모델에 대한 Train and Validate 진행\n",
    "\n",
    "* 코드 전체를 주석으로 설명하세요\n",
    "* Epoch 별로 Loss나 Accuracy를 출력하여 학습 진행 과정을 확인 할 수 있도록 합니다\n",
    "* 출력 예시는 주어지나 정해진 형식은 없습니다\n",
    "* 최적의 모델 저장\n",
    "\n",
    "예제:\n",
    "```\n",
    "Started Training...\n",
    "Epoch: 1 \tTraining Loss: 3.317162 \tValidation Loss: 4.162958\n",
    "Epoch: 2 \tTraining Loss: 2.420140 \tValidation Loss: 4.182362\n",
    "...\n",
    "...\n",
    "Finished training\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,x,y, transform =None):\n",
    "        self.x = x\n",
    "        self.y =y\n",
    "        self.transform = transform\n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        file_name = self.x[index]\n",
    "        img = Image.open(file_name).convert('RGB')\n",
    "        \n",
    "        label = self.y[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './imgs/train/'   # 이미지 경로 설정\n",
    "dataset = datasets.ImageFolder(root = train_path,) # datasets라이브러리의 ImageFolder함수로 train_path에 있는 데이터 불러옴\n",
    "classes = dataset.classes # 데이터의 class종류 확인\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True) \n",
    "# 데이터를 받으면 5개의 구간으로 나누어 valid셋과 train셋으로 나눠주고 5번fold 반복, 데이터 섞기(shuffle)\n",
    "\n",
    "def reset_weights(model): # 모델의 weights 값을 초기화 해주는 함수\n",
    "    for layer in model.children(): # 모델 전체의 모든 module에 대한 iterator를 반환한다.\n",
    "        if hasattr(layer, 'reset_parameters'): # reset_parameters가 존재한다면 layer의 파라미터 값을 리셋\n",
    "            layer.reset_parameters()\n",
    "\n",
    "n_epochs = 100 # epoch를 100으로 설정해 훈련함\n",
    "\n",
    "\n",
    "for fold, (train_ind, valid_ind) in enumerate(kf.split(dataset)): \n",
    "# 만든 kf에 ImageFolder인 dataset를 넣어 train_ind와 valid_ind를 불러옴\n",
    "\n",
    "    # Fold가 돌때마다 확인\n",
    "    print('Starting fold = ', fold)\n",
    "    # for문에서 불러온 index값을 이용해 train과 valid 데이터 분리\n",
    "    train_data = [dataset[i] for i in train_ind]\n",
    "    valid_data = [dataset[i] for i in valid_ind]\n",
    "    #print(train_data[0][0].show())\n",
    "    \n",
    "    # 만든 MyDataset class를 사용해 각 데이터의 transform 적용\n",
    "    train_data_kfold = MyDataset(\n",
    "       train_data, transform = train_transform)\n",
    "\n",
    "    valid_data_kfold = MyDataset(\n",
    "        valid_data, transform = valid_transform)\n",
    "    #print(valid_data_kfold.__getitem__(0))\n",
    "    \n",
    "    # pytorch에서 제공하는 DataLoader를 사용해 미니 배치 학습, 데이터 셔플(shuffle), 병렬 처리까지 간단히 수행가능 하도록 처리\n",
    "    train_loader_kfold = torch.utils.data.DataLoader(train_data_kfold, batch_size=16, shuffle=True)\n",
    "    valid_loader_kfold = torch.utils.data.DataLoader(valid_data_kfold, batch_size=8, shuffle=True)\n",
    "    # model에 ConvNet모델 적용\n",
    "    model = ConvNet()\n",
    "    # criterion변수값에 CrossEntropyLoss()값 불러오기\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optim의 Adam optimizer를 사용\n",
    "    # Adam은 가장 많이 쓰이는 optimizer 중 하나로 Momentum과 RMSProp를 융합한 방법이다. \n",
    "    optimizer = optim.Adam(model.parameters(), lr = 8e-5)\n",
    "    # scheduler는 StepLR를 사용하여 epoch을 40번 할때마다 lr의 값을 줄여주어 정확도의 최적값에 세밀하게 도달하는 효과를 준다.\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "    # fold를 돌때마다 model의 weigths값 초기화\n",
    "    model.apply(reset_weights)\n",
    "\n",
    "    valid_acc_max = 0.0 # valid 최고 정확도 값 초기설정\n",
    "\n",
    "    # loss값과 acc값을 저장하는 변수 생성\n",
    "    train_loss = torch.zeros(n_epochs)\n",
    "    valid_loss = torch.zeros(n_epochs)\n",
    "\n",
    "    train_acc = torch.zeros(n_epochs)\n",
    "    valid_acc = torch.zeros(n_epochs)\n",
    "    \n",
    "    # 훈련 for문 \n",
    "    for e in range(0, n_epochs):\n",
    "        model.train()   # model의 weight값들을 훈련하여 바뀌도록 설정\n",
    "        for data, labels in tqdm(train_loader_kfold): # tqdm을 사용하여 batch를 읽는 위치 확인\n",
    "            #만든 train dataloader 데이터셋 읽기\n",
    "            model.to(device) # gpu할당\n",
    "            data, labels = data.to(device), labels.to(device) # gpu할당\n",
    "\n",
    "            optimizer.zero_grad() # 이전에 계산된 기울기(미분값) 초기화\n",
    "            # forward pass\n",
    "            logits = model(data) # 데이터 모델 적용 / logit 값\n",
    "            \n",
    "            loss = criterion(logits, labels) # cross_entropy loss를 사용해 오차값 loss에 넣어줌\n",
    "            # backward pass\n",
    "            loss.backward() # 편미분을 통해 weights값을 갱신\n",
    "            \n",
    "            optimizer.step() # parameter 적용(업데이트)\n",
    "            # loss값 저장\n",
    "            train_loss[e] += loss.item()\n",
    "            \n",
    "            ps = F.softmax(logits, dim=1) # softmax를 사용해 logits값을 확률값으로 변환\n",
    "\n",
    "            top_class = torch.argmax(ps, dim=1) # 같은 행중에서 확률 값이 가장 큰 값을 예측값으로 결정\n",
    "\n",
    "            equals = top_class == labels.reshape(top_class.shape) # 예측한 값이 실제 값과 맞는지 확인\n",
    "            train_acc[e] += torch.mean(equals.type(torch.float)).detach().cpu() # 정답을 맞춘 정확도 확인\n",
    "\n",
    "        train_loss[e] /= len(train_loader_kfold) # 데이터의 loss들의 평균\n",
    "        train_acc[e] /= len(train_loader_kfold) # 데이터의 acc들의 평균\n",
    "\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad(): # gradient값 고정\n",
    "            model.eval() # 평가 모드 / dropout을 하지 않는다.\n",
    "            for data, labels in tqdm(valid_loader_kfold):\n",
    "\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "                # forward pass\n",
    "                logits = model(data)\n",
    "                # loss 계산\n",
    "                loss = criterion(logits, labels)\n",
    "                # valid loss 값\n",
    "                valid_loss[e] += loss.item()\n",
    "                # softmax 적용으로 logits값을 확률값으로 변환\n",
    "                ps = F.softmax(logits, dim=1)\n",
    "                # argmax로 확률 값 중 가장 큰 값을 예측값으로 설정\n",
    "                top_class = torch.argmax(ps, dim=1)\n",
    "                equals = top_class == labels.reshape(top_class.shape)\n",
    "                valid_acc[e] += torch.mean(equals.type(torch.float)).detach().cpu()\n",
    "\n",
    "        # loss와 acc의 평균 값 \n",
    "        valid_loss[e] /= len(valid_loader_kfold)\n",
    "        valid_acc[e] /= len(valid_loader_kfold)\n",
    "\n",
    "        # loss 출력\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            e, train_loss[e], valid_loss[e]))\n",
    "\n",
    "        # accuracy 출력\n",
    "        print('Epoch: {} \\tTraining accuracy: {:.6f} \\tValidation accuracy: {:.6f}'.format(\n",
    "            e, train_acc[e], valid_acc[e]))\n",
    "\n",
    "        # valid데이터의 accuracy 값이 가장 높은 모델 저장\n",
    "        if valid_acc[e] >= valid_acc_max:\n",
    "            print('Validation acc decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_acc_max,\n",
    "            valid_acc[e]))\n",
    "            # 각 fold마다 모델을 저장하기 위해 if문 사용\n",
    "            if fold == 0:\n",
    "                torch.save(model.state_dict(), 'model0.pt')\n",
    "            elif fold == 1:\n",
    "                torch.save(model.state_dict(), 'model1.pt')\n",
    "            elif fold == 2:\n",
    "                torch.save(model.state_dict(), 'model2.pt')\n",
    "            elif fold == 3:\n",
    "                torch.save(model.state_dict(), 'model3.pt')\n",
    "            else:\n",
    "                torch.save(model.state_dict(), 'model4.pt')\n",
    "            valid_acc_max = valid_acc[e]\n",
    "        print('best accuracy ({:.6f})'.format(valid_acc_max))\n",
    "        # Learning rate값에 scheduler 적용\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-commodity",
   "metadata": {},
   "source": [
    "## Step 6: CNN model training/validation 분석\n",
    "   * tranining loss와 validation loss 그래프를 통해서 분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold로 모델을 훈련하고 train과 valid에 대한 loss변화에 대한 시각적 분석\n",
    "# plt.plot(train_loss)\n",
    "# plt.plot(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold로 모델을 훈련하고 train과 valid에 대한 accuracy변화에 대한 시각적 분석\n",
    "# plt.plot(train_acc)\n",
    "# plt.plot(valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 파라미터값을 각 모델에 적용\n",
    "# gpu할당\n",
    "# eval모드로 설정하여 dropout을 하지 않음\n",
    "model0.load_state_dict(torch.load('model0.pt'))\n",
    "model0.to(device)\n",
    "model0.eval()\n",
    "\n",
    "model1.load_state_dict(torch.load('model1.pt'))\n",
    "model1.to(device)\n",
    "model1.eval()\n",
    "\n",
    "model2.load_state_dict(torch.load('model2.pt'))\n",
    "model2.to(device)\n",
    "model2.eval()\n",
    "\n",
    "model3.load_state_dict(torch.load('model3.pt'))\n",
    "model3.to(device)\n",
    "model3.eval()\n",
    "\n",
    "model4.load_state_dict(torch.load('model4.pt'))\n",
    "model4.to(device)\n",
    "model4.eval()\n",
    "\n",
    "model79_1.load_state_dict(torch.load('model79_1.pt'))\n",
    "model79_1.to(device)\n",
    "model79_1.eval()\n",
    "\n",
    "model79_2.load_state_dict(torch.load('model79_2.pt'))\n",
    "model79_2.to(device)\n",
    "model79_2.eval()\n",
    "\n",
    "model79_3.load_state_dict(torch.load('model79_3.pt'))\n",
    "model79_3.to(device)\n",
    "model79_3.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-press",
   "metadata": {},
   "source": [
    "## Step 7: Predict with Test Data \n",
    "\n",
    "\n",
    "### 예시 코드를 제공해 드립니다. 필요한 부분을 채워 사용하시거나 직접 코드를 작성 하셔도 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test데이터의 전처리 과정 Dataset을 input으로 받음\n",
    "class test_dataset(Dataset):\n",
    "    def __init__(self,imgpath,transform=None): # 이미지 경로와 transform을 받아옴\n",
    "        \n",
    "        self.imgpath = imgpath # self로 값을 받음\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self): # self 적용\n",
    "        return len(self.imgpath) # 받은 데이터의 길이 return\n",
    "    \n",
    "    def __getitem__(self,idx): # image의 idx로 순서대로 불러와 RGB 데이터 transform적용\n",
    "        x = self.transform(Image.open(self.imgpath[idx]).convert('RGB'))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid transform과 동일하게 적용\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4734, 0.4809, 0.4165), (0.1831, 0.1783, 0.1856)),\n",
    "    # 각 데이터의 mean과 std 정규화\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-jackson",
   "metadata": {},
   "source": [
    "### test dataset과 dataloader 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-program",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test데이터를 순서대로 불러옴\n",
    "test_set = sorted(glob.glob('./imgs/test/*'))\n",
    "test_batch = 1\n",
    "# transform 적용\n",
    "test_data = test_dataset(test_set,test_transform)\n",
    "# test의 순서롤 섞지않고 batch를 1로 주어 이미지를 하나씩 주는 dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=test_batch, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_data)) # test_set이 잘 들어왔나 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-disney",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# images, labels = next(iter(test_loader))\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-alfred",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "for i, data in enumerate(test_loader):\n",
    "\n",
    "    # 데이터를 list로 받음\n",
    "    inputs = []\n",
    "    inputs.append(data)\n",
    "    # stack으로 순서대로 데이터를 받고 gpu할당\n",
    "    inputs = torch.stack(inputs).to(device)\n",
    "    data = data.to(device)\n",
    "    # 각 모델에 data를 넣어 logit값을 뽑음\n",
    "    logit0 = model0(data)\n",
    "    logit1 = model1(data)\n",
    "    logit2 = model2(data)\n",
    "    logit3 = model3(data)\n",
    "    logit4 = model4(data)\n",
    "    logit79_1 = model79_1(data)\n",
    "    logit79_2 = model79_2(data)\n",
    "    logit79_3 = model79_3(data)\n",
    "    # 앙상블의 voting 방법을 사용하여 전체 logit값의 평균을 정함\n",
    "    logit = (logit0+logit1+logit2+logit3+logit4+logit79_1+logit79_2+logit79_3)/8\n",
    "    # 앙상블한 logit값에 softmax를 적용해 확률값으로 만듦\n",
    "    ps = F.softmax(logit)   \n",
    "    # 확률 값 중 가장 큰 값을 예측 값으로 결정\n",
    "    top_class = torch.argmax(ps, dim=1)  \n",
    "    # pred에 예측한 값을 testset순서대로 넣어줌\n",
    "    pred += [top_class.detach().cpu().numpy()]   \n",
    "    del logit   # logit값 초기화\n",
    "print(ps.shape)\n",
    "print(pred[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred의 값을 numpy array로 변환, int32 type로 바꿔줌\n",
    "pred1 = np.array(pred,dtype=np.int32)\n",
    "# 1차원으로 reshape\n",
    "pred1 = pred1.reshape(-1)\n",
    "pred1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측 값 확인\n",
    "pred1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-vessel",
   "metadata": {},
   "source": [
    "### Predict 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터의 label값을 classes변수에 넣어줌\n",
    "classes = [i.split('\\\\')[-1] for i in glob.glob('./imgs/train/*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-flour",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#클래스 종류 정렬 확인\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일 만드는 함수\n",
    "id=[]\n",
    "category =[]\n",
    "for i in range(len(test_set)):\n",
    "    id.append(test_set[i].split('\\\\')[-1])\n",
    "    category.append(classes[pred1[i]])\n",
    "pd.DataFrame({'Id':id,'Category':category}).to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-russian",
   "metadata": {},
   "source": [
    "예측 결과 인덱스를 저장한 pred 값을 사용해 클래스를 매칭하기 위한 class_name을 담아 놓은 리스트입니다.\n",
    "\n",
    "주의할 점은 Train과정에서 사용된 class lable값과 같은 순서로 저장이 되어 있어야 한다는 점입니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-proxy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
